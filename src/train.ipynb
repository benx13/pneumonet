{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting gdown\r\n",
      "  Downloading gdown-3.13.0.tar.gz (9.3 kB)\r\n",
      "  Installing build dependencies ... \u001B[?25l-\b \b\\\b \b|\b \b/\b \b-\b \bdone\r\n",
      "\u001B[?25h  Getting requirements to build wheel ... \u001B[?25l-\b \bdone\r\n",
      "\u001B[?25h    Preparing wheel metadata ... \u001B[?25l-\b \bdone\r\n",
      "\u001B[?25hCollecting filelock\r\n",
      "  Using cached filelock-3.0.12-py3-none-any.whl (7.6 kB)\r\n",
      "Collecting tqdm\r\n",
      "  Downloading tqdm-4.61.1-py2.py3-none-any.whl (75 kB)\r\n",
      "\u001B[K     |████████████████████████████████| 75 kB 1.1 MB/s eta 0:00:01\r\n",
      "\u001B[?25hCollecting requests[socks]>=2.12.0\r\n",
      "  Using cached requests-2.25.1-py2.py3-none-any.whl (61 kB)\r\n",
      "Requirement already satisfied: six in /Users/benx13/PycharmProjects/pythonProject/venv/lib/python3.8/site-packages (from gdown) (1.16.0)\r\n",
      "Collecting idna<3,>=2.5\r\n",
      "  Using cached idna-2.10-py2.py3-none-any.whl (58 kB)\r\n",
      "Collecting certifi>=2017.4.17\r\n",
      "  Downloading certifi-2021.5.30-py2.py3-none-any.whl (145 kB)\r\n",
      "\u001B[K     |████████████████████████████████| 145 kB 1.3 MB/s eta 0:00:01\r\n",
      "\u001B[?25hCollecting chardet<5,>=3.0.2\r\n",
      "  Using cached chardet-4.0.0-py2.py3-none-any.whl (178 kB)\r\n",
      "Collecting urllib3<1.27,>=1.21.1\r\n",
      "  Downloading urllib3-1.26.6-py2.py3-none-any.whl (138 kB)\r\n",
      "\u001B[K     |████████████████████████████████| 138 kB 985 kB/s eta 0:00:01\r\n",
      "\u001B[?25hCollecting PySocks!=1.5.7,>=1.5.6\r\n",
      "  Downloading PySocks-1.7.1-py3-none-any.whl (16 kB)\r\n",
      "Building wheels for collected packages: gdown\r\n",
      "  Building wheel for gdown (PEP 517) ... \u001B[?25l-\b \b\\\b \bdone\r\n",
      "\u001B[?25h  Created wheel for gdown: filename=gdown-3.13.0-py3-none-any.whl size=9034 sha256=a7ace3eaf025d30874d0af8241cd1687fb06907928950bd5b44f017935197361\r\n",
      "  Stored in directory: /Users/benx13/Library/Caches/pip/wheels/04/51/53/ed3e97af28b242e9eb81afb4836273fbe233a14228aa82fea3\r\n",
      "Successfully built gdown\r\n",
      "Installing collected packages: urllib3, idna, chardet, certifi, requests, PySocks, tqdm, filelock, gdown\r\n",
      "Successfully installed PySocks-1.7.1 certifi-2021.5.30 chardet-4.0.0 filelock-3.0.12 gdown-3.13.0 idna-2.10 requests-2.25.1 tqdm-4.61.1 urllib3-1.26.6\r\n",
      "\u001B[33mWARNING: You are using pip version 21.1.2; however, version 21.1.3 is available.\r\n",
      "You should consider upgrading via the '/Users/benx13/PycharmProjects/pythonProject/venv/bin/python -m pip install --upgrade pip' command.\u001B[0m\r\n",
      "Downloading...\r\n",
      "From: https://drive.google.com/uc?id=1--s5jizgawjG1MDWpfy-QtJ0Kp73TcPO\r\n",
      "To: /Users/benx13/PycharmProjects/pythonProject/pfe/DataCovRad.zip\r\n",
      "114MB [00:59, 1.78MB/s] ^C\r\n",
      "lf._handle_chunk(amt)\r\n",
      "  File \"/Users/benx13/PycharmProjects/pythonProject/venv/lib/python3.8/site-packages/urllib3/response.py\", line 711, in _handle_chunk\r\n",
      "    value = self._fp._safe_read(amt)\r\n",
      "  File \"/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.8/lib/python3.8/http/client.py\", line 608, in _safe_read\r\n",
      "    data = self.fp.read(amt)\r\n",
      "  File \"/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.8/lib/python3.8/socket.py\", line 669, in readinto\r\n",
      "    return self._sock.recv_into(b)\r\n",
      "  File \"/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.8/lib/python3.8/ssl.py\", line 1241, in recv_into\r\n",
      "    return self.read(nbytes, buffer)\r\n",
      "  File \"/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.8/lib/python3.8/ssl.py\", line 1099, in read\r\n",
      "    return self._sslobj.read(len, buffer)\r\n",
      "KeyboardInterrupt\r\n",
      "114MB [01:00, 1.90MB/s]\r\n"
     ]
    }
   ],
   "source": [
    "from torchvision.io.image import read_image\n",
    "from torchvision.transforms.functional import normalize, resize, to_pil_image\n",
    "from torchvision.models import resnet18\n",
    "from torchcam.cams import SmoothGradCAMpp\n",
    "from torchcam.cams import ScoreCAM\n",
    "from torchcam.cams import CAM\n",
    "from torchcam.utils import overlay_mask\n",
    "\n",
    "from pfe.EarlyStop.EarlyStop import EarlyStopping\n",
    "!pip install imutils\n",
    "!pip install pytorchtools\n",
    "import numpy as np\n",
    "#%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import torch\n",
    "from torchvision import datasets, models, transforms\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torch\n",
    "from imutils import paths\n",
    "import random\n",
    "import cv2\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torch.utils.data import Subset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torchvision.transforms import Compose, ToTensor, Resize\n",
    "from torch.utils.data import DataLoader\n",
    "from pfe.Dataset.Dataset import XrayData\n",
    "from tqdm import tqdm\n",
    "import torch.nn.functional as F\n",
    "from math import floor, ceil\n",
    "import shutil\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import pandas as pd\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import seaborn as sns\n",
    "import os\n",
    "from pfe.utils.utils import get_mean_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "BATCH = 32\n",
    "EPOCH = 64\n",
    "lr = 1e-4"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "data": {
      "text/plain": "0.0001"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = Compose([ transforms.ToPILImage(),transforms.Resize((224,224),interpolation=Image.NEAREST), transforms.ToTensor()])\n",
    "\n",
    "dataset = XrayData(['/kaggle/working/CovRad/BS', '/kaggle/working/Mendeley/BS'], transforms=t, enhanced=False, segmented=False, gamma=2)\n",
    "train_set, test_set = torch.utils.data.random_split(dataset, [floor(len(dataset) * 0.8), ceil(len(dataset)*0.2)])\n",
    "train_loader = DataLoader(train_set, batch_size=1, shuffle=True)\n",
    "test_loader = DataLoader(test_set, batch_size=1, shuffle=True)\n",
    "mean, std = get_mean_std(train_loader)\n",
    "mean, std"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-3-cd2dc5ec1099>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[0;32m----> 1\u001B[0;31m \u001B[0mbatch\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0m_\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mnext\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0miter\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mdataset\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      2\u001B[0m \u001B[0mplt\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mimshow\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mbatch\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;36m0\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mcmap\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;34m'gray'\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      3\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mNameError\u001B[0m: name 'dataset' is not defined"
     ]
    }
   ],
   "source": [
    "batch, _ = next(iter(dataset))\n",
    "plt.imshow(batch[0], cmap='gray')\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "t = Compose([transforms.ToPILImage(),\n",
    "                   transforms.Resize((224,224),\n",
    "                   interpolation=Image.NEAREST),\n",
    "                   transforms.RandomHorizontalFlip(),\n",
    "                   transforms.RandomVerticalFlip(),\n",
    "                   transforms.ToTensor(),\n",
    "                   transforms.Normalize(mean, std)])\n",
    "\n",
    "dataset = XrayData(['/kaggle/working/CovRad/BS', '/kaggle/working/Mendeley/BS'], transforms=t, enhanced=False, segmented=False, gamma=2)\n",
    "train_set, test_set = torch.utils.data.random_split(dataset, [floor(len(dataset) * 0.8), ceil(len(dataset)*0.2)])\n",
    "train_loader = DataLoader(train_set, batch_size=BATCH, shuffle=True)\n",
    "test_loader = DataLoader(test_set, batch_size=BATCH, shuffle=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'torch' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-4-8ff8eae8d4de>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[0;32m----> 1\u001B[0;31m \u001B[0mdevice\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mtorch\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdevice\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m'cuda'\u001B[0m \u001B[0;32mif\u001B[0m \u001B[0mtorch\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mcuda\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mis_available\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;32melse\u001B[0m \u001B[0;34m'cpu'\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      2\u001B[0m \u001B[0mdevice\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mNameError\u001B[0m: name 'torch' is not defined"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'models' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-6-a90e9acef6b6>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[0;32m----> 1\u001B[0;31m \u001B[0mmodel\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mmodels\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mresnet18\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mpretrained\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;32mTrue\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      2\u001B[0m \u001B[0mmodel\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mfc\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mnn\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mLinear\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;36m512\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;36m4\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      3\u001B[0m \u001B[0mmodel\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mto\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mdevice\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      4\u001B[0m \u001B[0mcriterion\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mnn\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mCrossEntropyLoss\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      5\u001B[0m \u001B[0mSGDM\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mtorch\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0moptim\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mAdam\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mmodel\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mparameters\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mlr\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mlr\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mNameError\u001B[0m: name 'models' is not defined"
     ]
    }
   ],
   "source": [
    "model = models.resnet18(pretrained=True)\n",
    "model.fc = nn.Linear(512, 4)\n",
    "model.to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "SGDM = torch.optim.Adam(model.parameters(), lr=lr)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "def train(model=None, loss=None, optimizer=None, epochs=64, patience=5):\n",
    "    # Train the model\n",
    "    total_step = len(train_loader)\n",
    "    train_loss = []\n",
    "    train_acc = []\n",
    "    val_loss = []\n",
    "    val_acc = []\n",
    "    conf_mats = []\n",
    "    checkpoint_path = './best_checkpoint_dict.pt'\n",
    "    best_model_path = './best_model.pt'\n",
    "    val_loss_min = 1\n",
    "\n",
    "    early_stopping = EarlyStopping(patience=patience, verbose=True)\n",
    "\n",
    "    for epoch in tqdm(range(epochs)):\n",
    "        acc = []\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        # Training step\n",
    "        for i, (images, labels) in enumerate(train_loader):\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "\n",
    "            # Backward and optimize\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            _, outputs = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (labels == outputs).sum()\n",
    "            acc.append((correct/total).item())\n",
    "\n",
    "\n",
    "        print(\"Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}, Acc: {:.4f}\".format(epoch+1, EPOCH, i+1, total_step, loss.item(), np.mean(acc)))\n",
    "        train_loss.append(loss.item())\n",
    "        train_acc.append(np.mean(acc))\n",
    "\n",
    "        # Validation step\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        v_loss = []\n",
    "        v_acc = []\n",
    "        confusion_matrix = torch.zeros(4, 4)\n",
    "        for images, labels in test_loader:\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            predictions = model(images)\n",
    "            _, predicted = torch.max(predictions, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (labels == predicted).sum()\n",
    "            loss = criterion(predictions, labels)\n",
    "            v_loss.append(loss.item())\n",
    "            v_acc.append((correct/total).item())\n",
    "\n",
    "            for t, p in zip(labels.view(-1), predicted.view(-1)):\n",
    "                confusion_matrix[t.long(), p.long()] += 1\n",
    "            conf_mats.append(confusion_matrix)\n",
    "\n",
    "\n",
    "        print('Val Loss: {:.4f}, Val Acc: {:.4f}'.format(np.mean(v_loss), correct/total))\n",
    "        val_acc.append((correct/total).item())\n",
    "        val_loss.append(np.mean(v_loss))\n",
    "\n",
    "\n",
    "        train_history = {\n",
    "        'train_loss': train_loss,\n",
    "        'val_loss': val_loss,\n",
    "        'train_acc': train_acc,\n",
    "        'val_acc': val_acc,\n",
    "        'confusion_matrix':conf_mats\n",
    "        }\n",
    "        checkpoint = {\n",
    "            'epoch': epoch,\n",
    "            'state_dict': model.state_dict(),\n",
    "            'optimizer': optimizer.state_dict(),\n",
    "            'Trainig_History' : train_history,\n",
    "        }\n",
    "\n",
    "        # save checkpoint\n",
    "        #save_ckp(checkpoint, False, checkpoint_path, best_model_path)\n",
    "\n",
    "        ## TODO: save the model if validation loss has decreased\n",
    "        #if np.mean(v_loss) < val_loss_min:\n",
    "            #print('Validation loss decreased ({:.6f} --> {:.6f}).  Saving model ...'.format(val_loss_min,np.mean(v_loss)))\n",
    "            # save checkpoint as best model\n",
    "            #save_ckp(checkpoint, True, checkpoint_path, best_model_path)\n",
    "            #val_loss_min = np.mean(v_loss)\n",
    "\n",
    "\n",
    "        early_stopping(np.mean(v_loss), model)\n",
    "        if early_stopping.early_stop:\n",
    "            print(\"Early stopping\")\n",
    "            break\n",
    "\n",
    "    model.load_state_dict(torch.load('checkpoint.pt'))\n",
    "    torch.save(train_history, 'train_h.pt')\n",
    "    return model, train_history"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-10-13b2673af384>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[0;32m----> 1\u001B[0;31m \u001B[0mmodel\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mt_h\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mtrain\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mmodel\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mmodel\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mloss\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mcriterion\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0moptimizer\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mSGDM\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mepochs\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;36m128\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mpatience\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;36m20\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "model, t_h = train(model=model, loss=criterion, optimizer=SGDM, epochs=128, patience=20)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-12-7bf6649e5e9d>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[0;31m# visualize the loss as the network trained\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 2\u001B[0;31m \u001B[0mfig\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mplt\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mfigure\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mfigsize\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;36m10\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;36m8\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      3\u001B[0m \u001B[0mplt\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mplot\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mrange\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;36m1\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0mlen\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mt_h\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m'train_loss'\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m+\u001B[0m\u001B[0;36m1\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0mt_h\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m'train_loss'\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mlabel\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;34m'Training Loss'\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      4\u001B[0m \u001B[0mplt\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mplot\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mrange\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;36m1\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0mlen\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mt_h\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m'val_loss'\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m+\u001B[0m\u001B[0;36m1\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0mt_h\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m'val_loss'\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0mlabel\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;34m'Validation Loss'\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      5\u001B[0m \u001B[0mplt\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mplot\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mrange\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;36m1\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0mlen\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mt_h\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m'train_acc'\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m+\u001B[0m\u001B[0;36m1\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0mt_h\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m'train_acc'\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mlabel\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;34m'Training Accuracy'\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mNameError\u001B[0m: name 'plt' is not defined"
     ]
    }
   ],
   "source": [
    "# visualize the loss as the network trained\n",
    "fig = plt.figure(figsize=(10,8))\n",
    "plt.plot(range(1,len(t_h['train_loss'])+1),t_h['train_loss'], label='Training Loss')\n",
    "plt.plot(range(1,len(t_h['val_loss'])+1),t_h['val_loss'],label='Validation Loss')\n",
    "plt.plot(range(1,len(t_h['train_acc'])+1),t_h['train_acc'], label='Training Accuracy')\n",
    "plt.plot(range(1,len(t_h['val_acc'])+1),t_h['val_acc'],label='Validation Accuracy')\n",
    "\n",
    "# find position of lowest validation loss\n",
    "minposs = t_h['val_loss'].index(min(t_h['val_loss']))+1\n",
    "plt.axvline(minposs, linestyle='--', color='r',label='Early Stopping Checkpoint')\n",
    "\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('loss/acc')\n",
    "plt.ylim(0, 1.1) # consistent scale\n",
    "plt.xlim(0, len(t_h['train_loss'])+1) # consistent scale\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "fig.savefig('loss_plot.png', bbox_inches='tight')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'np' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-13-82e6494e28d2>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[0;32m----> 1\u001B[0;31m \u001B[0mprint\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m'Min Loss : '\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mnp\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mmin\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mt_h\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m'val_loss'\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m' Avg : '\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mnp\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mmean\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mt_h\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m'val_loss'\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;36m3\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;36m15\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      2\u001B[0m \u001B[0mprint\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m'Max Acc : '\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mnp\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mmax\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mt_h\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m'val_acc'\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m' Avg : '\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mnp\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mmean\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mt_h\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m'val_acc'\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;36m3\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;36m15\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mNameError\u001B[0m: name 'np' is not defined"
     ]
    }
   ],
   "source": [
    "print('Min Loss : ', np.min(t_h['val_loss']), ' Avg : ', np.mean(t_h['val_loss'][3:15]))\n",
    "print('Max Acc : ', np.max(t_h['val_acc']), ' Avg : ', np.mean(t_h['val_acc'][3:15]))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'torch' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-14-5bfec928db87>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      2\u001B[0m \u001B[0my_pred_list\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      3\u001B[0m \u001B[0my_test_list\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 4\u001B[0;31m \u001B[0;32mwith\u001B[0m \u001B[0mtorch\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mno_grad\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      5\u001B[0m     \u001B[0mmodel\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0meval\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      6\u001B[0m     \u001B[0;32mfor\u001B[0m \u001B[0mX_batch\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0my_tag\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mtest_loader\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mNameError\u001B[0m: name 'torch' is not defined"
     ]
    }
   ],
   "source": [
    "flatten = lambda t: [item for sublist in t for item in sublist]\n",
    "y_pred_list = []\n",
    "y_test_list = []\n",
    "with torch.no_grad():\n",
    "    model.eval()\n",
    "    for X_batch, y_tag in test_loader:\n",
    "        #print(y_tag.tolist())\n",
    "        X_batch = X_batch.to(device)\n",
    "        y_test_pred = model(X_batch).cpu()\n",
    "        _, y_pred_tags = torch.max(y_test_pred, dim = 1)\n",
    "        y_pred_list.append(y_pred_tags.cpu().numpy())\n",
    "        y_test_list.append(y_tag.tolist())\n",
    "y_pred_list = [a.squeeze().tolist() for a in y_pred_list]\n",
    "y_pred_list = flatten(y_pred_list)\n",
    "y_test_list = flatten(y_test_list)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-15-3e4f908a77f3>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[0mtarget_names\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;34m{\u001B[0m\u001B[0;36m0\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m'Normal'\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;36m1\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m'Covid'\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;36m2\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\"Lung_Opacity\"\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;36m3\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m'Pneumonia'\u001B[0m\u001B[0;34m}\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 2\u001B[0;31m confusion_matrix_df = pd.DataFrame(\n\u001B[0m\u001B[1;32m      3\u001B[0m     confusion_matrix(np.array(y_test_list),\n\u001B[1;32m      4\u001B[0m                      np.array(y_pred_list))).rename(\n\u001B[1;32m      5\u001B[0m     columns=target_names, index=target_names)\n",
      "\u001B[0;31mNameError\u001B[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "target_names={0:'Normal', 1:'Covid', 2:\"Lung_Opacity\", 3:'Pneumonia'}\n",
    "confusion_matrix_df = pd.DataFrame(\n",
    "    confusion_matrix(np.array(y_test_list),\n",
    "                     np.array(y_pred_list))).rename(\n",
    "    columns=target_names, index=target_names)\n",
    "\n",
    "plt.figure(figsize=(10,8))\n",
    "sns.heatmap(confusion_matrix_df, annot=True, fmt='g')\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'classification_report' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-16-e9d79aa4a427>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[0;32m----> 1\u001B[0;31m \u001B[0mprint\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mclassification_report\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0my_test_list\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0my_pred_list\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtarget_names\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m'Normal'\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m'Covid'\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m\"Lung_Opacity\"\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m'Pneumonia'\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mdigits\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;36m4\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      2\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      3\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mNameError\u001B[0m: name 'classification_report' is not defined"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test_list, y_pred_list, target_names=['Normal', 'Covid', \"Lung_Opacity\", 'Pneumonia'], digits=4))\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ScoreCAM' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-17-c06448866a50>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[0;32m----> 1\u001B[0;31m \u001B[0mcam_extractor\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mScoreCAM\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mmodel\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      2\u001B[0m \u001B[0mX_batch\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0my_tag\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mnext\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0miter\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtest_loader\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mNameError\u001B[0m: name 'ScoreCAM' is not defined"
     ]
    }
   ],
   "source": [
    "cam_extractor = ScoreCAM(model)\n",
    "X_batch, y_tag = next(iter(test_loader))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_batch' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-18-bdd8b50f4ab6>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[0;32mfor\u001B[0m \u001B[0mi\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mrange\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;36m32\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 2\u001B[0;31m     \u001B[0mimg\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mX_batch\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mi\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      3\u001B[0m     \u001B[0my_test_pred\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mmodel\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mimg\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0munsqueeze\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;36m0\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mto\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mdevice\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mcpu\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      4\u001B[0m     \u001B[0m_\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0my_pred_tags\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mtorch\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mmax\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0my_test_pred\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mdim\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;36m1\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      5\u001B[0m     \u001B[0;32mif\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0my_pred_tags\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mitem\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m==\u001B[0m\u001B[0;36m3\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mNameError\u001B[0m: name 'X_batch' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "for i in range(32):\n",
    "    img = X_batch[i]\n",
    "    y_test_pred = model(img.unsqueeze(0).to(device)).cpu()\n",
    "    _, y_pred_tags = torch.max(y_test_pred, dim = 1)\n",
    "    if(y_pred_tags.item()==3):\n",
    "        print(target_names[y_pred_tags.item()])\n",
    "        activation_map = cam_extractor(y_test_pred.squeeze(0).argmax().item(), y_test_pred)\n",
    "        z = img * torch.tensor(std).view(3, 1, 1)\n",
    "        z = z + torch.tensor(mean).view(3, 1, 1)\n",
    "        result = overlay_mask(to_pil_image(z), to_pil_image(activation_map, mode='F'), alpha=0.5)\n",
    "        # Display it\n",
    "        plt.imshow(result); plt.axis('off'); plt.tight_layout(); plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}